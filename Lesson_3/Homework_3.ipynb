{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание\n",
    "## Урок 3. Классификация. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred, epsilon=1e-8):\n",
    "    y = y.astype(np.float64)            # Привожу к типу вещественному,\n",
    "    y_pred = y_pred.astype(np.float64)  # иначе ошибка в первом примере состоящем только из целых нудей и единиц\n",
    "    \n",
    "    y_pred[y_pred > 1 - epsilon] = 1 - epsilon  # Ограничим значения предсказанных значений интервалом [epsilon; 1 - epsilon]\n",
    "    y_pred[y_pred < epsilon] = epsilon\n",
    "    \n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000100247594e-08"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1      = np.array([1, 0, 0, 1])\n",
    "y_pred1 = np.array([1, 0, 0, 1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052680262828913194"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array(     [ 1, 0,  0, 1])\n",
    "y_pred1 = np.array([.9, 0, .1, 1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array( [0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations=10000, alpha=1e-4, silent=False):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        \n",
    "        if not silent:\n",
    "            if i % (iterations / 10) == 0:\n",
    "                print(i, W, err)\n",
    "    return W, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значения log loss при разных alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1.2198772782390879 [ 0.49667518 -0.13838259  0.6476866   1.52297221]\n",
      "1e-07 1.2181827241996186 [ 0.49632455 -0.13944699  0.64766909  1.52245353]\n",
      "1e-06 1.201296577757615 [ 0.49282758 -0.1500751   0.64748968  1.51727929]\n",
      "1e-05 1.0393648355410017 [ 0.45886981 -0.25439705  0.6453131   1.46695998]\n",
      "0.0001 0.5906743816929662 [ 0.25808924 -0.68189547  0.68834749  1.2411954 ]\n",
      "0.001 0.5233563729128639 [-0.29756287 -0.72669083  1.06148576  1.39664388]\n",
      "0.01 0.4058305387773311 [-2.77079473 -0.99580928  0.56650766  3.2676589 ]\n"
     ]
    }
   ],
   "source": [
    "for a in np.power(10, np.arange(-8, -1), dtype=np.float64):\n",
    "    w, err = eval_model(X_st, y, alpha=a, silent=True)\n",
    "    print(a, err, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем $\\alpha = 0.1$. Число итераций 10 000.\n",
    "\n",
    "А вообще с ростом числа итераций и $\\alpha$, видим, что log loss уменьшается, но коэффициенты становятся огромными. Кажется, нужна регуляризация для избежания переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем предсказания для выбранных нами параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-2.77136565 -0.99588853  0.56641089  3.26813012] 0.40587815270727734\n",
      "2000 [-4.59094777 -1.0359998  -0.13825631  4.44501211] 0.35333924193451927\n",
      "3000 [-5.91004767 -1.08773886 -0.62127728  5.36155604] 0.32501347614925347\n",
      "4000 [-6.96133333 -1.14371437 -0.98694403  6.13057114] 0.3066241878369146\n",
      "5000 [-7.85498033 -1.19935714 -1.28748713  6.80564285] 0.2931244675498327\n",
      "6000 [-8.64731257 -1.25347799 -1.54786532  7.41682354] 0.28239334043313835\n",
      "7000 [-9.36966717 -1.30586395 -1.78130777  7.98193089] 0.27340382430941684\n",
      "8000 [-10.04075209  -1.35657036  -1.99546097   8.51208184] 0.26560192980297875\n",
      "9000 [-10.67239108  -1.40571631  -2.1950503    9.01453862] 0.2586628760279488\n",
      "10000 [-11.27241705  -1.45342424  -2.38315559   9.49424167] 0.2523832489493557\n"
     ]
    }
   ],
   "source": [
    "w, err = eval_model(X_st, y, alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.dot(w, X_st)\n",
    "y_pred = sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2896499 , 0.13238445, 0.99730871, 0.19963747, 0.73522164,\n",
       "       0.28534702, 0.99936607, 0.08615041, 0.34268615, 0.99086395])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    z = np.dot(W, X)\n",
    "    y_pred_proba = sigmoid(z)\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2896499 , 0.13238445, 0.99730871, 0.19963747, 0.73522164,\n",
       "       0.28534702, 0.99936607, 0.08615041, 0.34268615, 0.99086395])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(w, X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, treshold=.5):\n",
    "    z = np.dot(W, X)\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    y_pred = np.where(y_pred < treshold, \n",
    "                      np.zeros(y_pred.shape), \n",
    "                      np.ones(y_pred.shape))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(w, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred(w, X_st, treshold=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  <empty>   | $$y_{true} = 1$$ | $$y_{true} = 0$$ |\n",
    "--- | --- | ---\n",
    "| __$$y_{pred} = 1$$__  |   TP    |   FP   |\n",
    "| __$$y_{pred} = 0$$__ |   FN    |   TN   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.count_nonzero(y_true == y_pred) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    y_true = y_true.astype(np.int)\n",
    "    y_pred = y_pred.astype(np.int)\n",
    "    m = np.zeros((2, 2))\n",
    "    for i in range(len(y_true)):\n",
    "        m[1 - y_true[i]][1 - y_pred[i]] += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    m = confusion_matrix(y, y_pred)\n",
    "    return m[0][0] / (m[0][0] + m[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    m = confusion_matrix(y, y_pred)\n",
    "    return m[0][0] / (m[0][0] + m[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 1.],\n",
       "       [0., 5.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888888888888889"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, могла. \n",
    "\n",
    "С неконтролируемым ростом коэффициентов модели сигмоида как бы поощряет огромные значения <W, X>. Ведь они становятся ближе к 0 при стремлении к минус бесконечности и ближе к 1 при стремлении к + бесконечности. \n",
    "\n",
    "По крайней мере так на нашем примере. Ошибка log loss становится все меньше с ростом итераций и/или шага градиентого спуска. Коэффициенты модели становятся огромными. \n",
    "\n",
    "На новых тестовых значениях результаты скорее всего будут плохие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7*. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
