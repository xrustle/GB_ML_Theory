{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание\n",
    "## Урок 1. Алгоритм линейной регрессии. Градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1,  1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 59, 65, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(X @ X.T) @ X @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[1,:], y)\n",
    "plt.plot(X[1], w[0] + w[1] * X[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Подберите скорость обучения (alpha) и количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[1]\n",
    "w = np.array([1, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный код поместил в функцию и добавил подсчет дистанции между новым вектором весов и вектором весов с предыдущего шага.\n",
    "\n",
    "Как только расстояние становится меньше $10^{-8}$, алгоритм останавливаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc(alpha):\n",
    "    W = w.copy()\n",
    "    for i in range(1000):\n",
    "        y_pred = np.dot(W, X)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        old_W = W.copy()\n",
    "\n",
    "        for ii in range(W.shape[0]):\n",
    "            W[ii] -= alpha * (1/n * 2 * np.sum(X[ii] * (y_pred - y)))\n",
    "\n",
    "        weight_dist = np.linalg.norm(W - old_W, ord=2)\n",
    "\n",
    "#         if i % 30 == 0:\n",
    "#             print(i, W, err, weight_dist)\n",
    "\n",
    "        if weight_dist < 1e-8:\n",
    "            return i, W\n",
    "            break\n",
    "    return i, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем шаг $\\alpha$ среди значений  от $0.01$ до $0.07$ с шагом $0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(1e-2, 7e-2, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 (999, array([47.23086913,  3.91094949]))\n",
      "0.011 (999, array([47.23169769,  3.91079649]))\n",
      "0.011999999999999999 (999, array([47.23198744,  3.91074298]))\n",
      "0.012999999999999998 (999, array([47.23208866,  3.91072429]))\n",
      "0.013999999999999997 (999, array([47.23212398,  3.91071777]))\n",
      "0.014999999999999996 (999, array([47.23213629,  3.9107155 ]))\n",
      "0.015999999999999993 (999, array([47.23214057,  3.91071471]))\n",
      "0.016999999999999994 (999, array([47.23214206,  3.91071443]))\n",
      "0.017999999999999995 (966, array([47.23214234,  3.91071438]))\n",
      "0.018999999999999993 (918, array([47.23214238,  3.91071437]))\n",
      "0.01999999999999999 (874, array([47.2321424 ,  3.91071437]))\n",
      "0.02099999999999999 (834, array([47.23214242,  3.91071437]))\n",
      "0.021999999999999992 (798, array([47.23214245,  3.91071436]))\n",
      "0.02299999999999999 (764, array([47.23214246,  3.91071436]))\n",
      "0.023999999999999987 (734, array([47.23214248,  3.91071436]))\n",
      "0.024999999999999988 (706, array([47.2321425 ,  3.91071435]))\n",
      "0.02599999999999999 (680, array([47.23214251,  3.91071435]))\n",
      "0.02699999999999999 (655, array([47.23214252,  3.91071435]))\n",
      "0.027999999999999983 (633, array([47.23214253,  3.91071435]))\n",
      "0.028999999999999984 (612, array([47.23214255,  3.91071434]))\n",
      "0.029999999999999985 (592, array([47.23214255,  3.91071434]))\n",
      "0.030999999999999986 (574, array([47.23214257,  3.91071434]))\n",
      "0.03199999999999998 (557, array([47.23214258,  3.91071434]))\n",
      "0.03299999999999998 (540, array([47.23214258,  3.91071434]))\n",
      "0.03399999999999998 (525, array([47.23214259,  3.91071433]))\n",
      "0.03499999999999998 (511, array([47.23214261,  3.91071433]))\n",
      "0.035999999999999976 (497, array([47.23214261,  3.91071433]))\n",
      "0.03699999999999998 (484, array([47.23214262,  3.91071433]))\n",
      "0.03799999999999998 (472, array([47.23214263,  3.91071433]))\n",
      "0.03899999999999998 (460, array([47.23214263,  3.91071433]))\n",
      "0.03999999999999997 (449, array([47.23214264,  3.91071433]))\n",
      "0.040999999999999974 (438, array([47.23214264,  3.91071433]))\n",
      "0.041999999999999975 (428, array([47.23214265,  3.91071432]))\n",
      "0.042999999999999976 (418, array([47.23214265,  3.91071432]))\n",
      "0.04399999999999998 (409, array([47.23214265,  3.91071432]))\n",
      "0.04499999999999997 (400, array([47.23214266,  3.91071432]))\n",
      "0.04599999999999997 (392, array([47.23214267,  3.91071432]))\n",
      "0.04699999999999997 (384, array([47.23214267,  3.91071432]))\n",
      "0.047999999999999966 (376, array([47.23214267,  3.91071432]))\n",
      "0.04899999999999997 (369, array([47.23214268,  3.91071432]))\n",
      "0.04999999999999997 (361, array([47.23214268,  3.91071432]))\n",
      "0.05099999999999997 (354, array([47.23214268,  3.91071432]))\n",
      "0.05199999999999997 (348, array([47.23214269,  3.91071432]))\n",
      "0.052999999999999964 (341, array([47.23214269,  3.91071432]))\n",
      "0.053999999999999965 (335, array([47.23214269,  3.91071432]))\n",
      "0.054999999999999966 (329, array([47.2321427 ,  3.91071432]))\n",
      "0.05599999999999996 (324, array([47.23214271,  3.91071431]))\n",
      "0.05699999999999996 (318, array([47.23214271,  3.91071431]))\n",
      "0.05799999999999996 (313, array([47.23214271,  3.91071431]))\n",
      "0.05899999999999996 (307, array([47.23214271,  3.91071431]))\n",
      "0.05999999999999996 (302, array([47.23214271,  3.91071431]))\n",
      "0.06099999999999996 (298, array([47.23214272,  3.91071431]))\n",
      "0.06199999999999996 (293, array([47.23214272,  3.91071431]))\n",
      "0.06299999999999996 (288, array([47.23214272,  3.91071431]))\n",
      "0.06399999999999995 (299, array([47.23214281,  3.91071429]))\n",
      "0.06499999999999995 (534, array([47.23214286,  3.91071429]))\n",
      "0.06599999999999995 (999, array([47.23197833,  3.90982329]))\n",
      "0.06699999999999995 (999, array([-1.74575854e+09, -9.45402799e+09]))\n",
      "0.06799999999999995 (999, array([-7.7338821e+21, -4.1882273e+22]))\n",
      "0.06899999999999995 (999, array([-1.50297072e+34, -8.13922803e+34]))\n"
     ]
    }
   ],
   "source": [
    "for a in alphas:\n",
    "    print(a, grad_desc(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь поищем лучший шаг $\\alpha$ среди значений  от $0.062$ до $0.064$ с шагом $0.0001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(.062, .064, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.062 (293, array([47.23214272,  3.91071431]))\n",
      "0.0621 (292, array([47.23214272,  3.91071431]))\n",
      "0.062200000000000005 (292, array([47.23214272,  3.91071431]))\n",
      "0.06230000000000001 (291, array([47.23214272,  3.91071431]))\n",
      "0.06240000000000001 (291, array([47.23214272,  3.91071431]))\n",
      "0.06250000000000001 (291, array([47.23214272,  3.91071431]))\n",
      "0.06260000000000002 (290, array([47.23214272,  3.91071431]))\n",
      "0.06270000000000002 (290, array([47.23214272,  3.91071431]))\n",
      "0.06280000000000002 (289, array([47.23214272,  3.91071431]))\n",
      "0.06290000000000003 (289, array([47.23214272,  3.91071431]))\n",
      "0.06300000000000003 (288, array([47.23214272,  3.91071431]))\n",
      "0.06310000000000003 (288, array([47.23214272,  3.91071431]))\n",
      "0.06320000000000003 (287, array([47.23214272,  3.91071431]))\n",
      "0.06330000000000004 (287, array([47.23214272,  3.91071431]))\n",
      "0.06340000000000004 (287, array([47.23214273,  3.91071431]))\n",
      "0.06350000000000004 (286, array([47.23214272,  3.91071431]))\n",
      "0.06360000000000005 (286, array([47.23214273,  3.91071431]))\n",
      "0.06370000000000005 (285, array([47.23214272,  3.91071431]))\n",
      "0.06380000000000005 (286, array([47.23214273,  3.91071431]))\n",
      "0.06390000000000005 (290, array([47.23214277,  3.91071431]))\n",
      "0.06400000000000006 (299, array([47.23214281,  3.91071429]))\n"
     ]
    }
   ],
   "source": [
    "for a in alphas:\n",
    "    print(a, grad_desc(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что в данной задаче при $\\alpha = 0.0637$ за $285$ шагов дойдем до минимума с заданной точностью $10^{-8}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.* В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0637\n",
    "W = np.array([1, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.sum(X * (y_pred - y))` заменил на `X @ (y_pred - y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 8.01974 22.158  ] 3173.15\n",
      "30 [42.12976616  5.79122214] 78.19113705241716\n",
      "60 [46.57198203  4.11261092] 46.32793189825305\n",
      "90 [47.14704522  3.93324774] 45.9428929854584\n",
      "120 [47.22120004  3.91331634] 45.93758104968297\n",
      "150 [47.23073796  3.91102327] 45.937501274581834\n",
      "180 [47.23196268  3.91075178] 45.937500020491576\n",
      "210 [47.23211977  3.91071891] 45.93750000033283\n",
      "240 [47.2321399   3.91071486] 45.937500000005414\n",
      "270 [47.23214248  3.91071436] 45.93750000000008\n",
      "300 [47.23214281  3.91071429] 45.93749999999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(301):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#   for ii in range(W.shape[0]):\n",
    "#       W[ii] -= alpha * (1/n * 2 * np.sum(X[ii] * (y_pred - y)))\n",
    "\n",
    "#   W -= (alpha * (1/n * 2 * np.sum(X * (y_pred - y))))\n",
    "\n",
    "    W -= alpha * (1/n * 2 * X @ (y_pred - y))\n",
    "    if i % 30 == 0:\n",
    "        print(i, W, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.* Вместо того, чтобы задавать количество итераций, задайте условие остановки алгоритма - когда ошибка за итерацию начинает изменяться ниже определенного порога (упрощенный аналог параметра tol в линейной регрессии в sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc_2(alpha):\n",
    "    W = w.copy()\n",
    "    max_iter = 10000  # Ограничение числа итераций для избежания зацикливания\n",
    "    min_err_dist = 1e-8  # критерий сходимости (разница ошибок, при которой алгоритм останавливается)\n",
    "    err = np.inf  # Начальная ошибка\n",
    "    iter_num = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        y_pred = np.dot(W, X)\n",
    "        W -= alpha * (1/n * 2 * X @ (y_pred - y))\n",
    "            \n",
    "        err_new = calc_mse(y, y_pred)\n",
    "        err_dist = err - err_new\n",
    "        if err_dist < min_err_dist:\n",
    "            break\n",
    "        \n",
    "        err = err_new\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'{i:<5} {str(W):<27} {err:<14.8f} {err_dist:.8f}')\n",
    "\n",
    "    return i, W, err, err_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [ 8.01974 22.158  ]         3173.15000000  inf\n",
      "10    [27.34592281 12.42696124]   714.68292287   110.93253667\n",
      "20    [37.15543166  7.90342597]   191.47361195   23.83801148\n",
      "30    [42.12976616  5.79122214]   78.19113705    5.21430864\n",
      "40    [44.65014667  4.80046746]   53.21692160    1.16159317\n",
      "50    [45.92625981  4.33360951]   47.60957850    0.26349548\n",
      "60    [46.57198203  4.11261092]   46.32793190    0.06081506\n",
      "70    [46.89854838  4.00752124]   46.03002752    0.01426255\n",
      "80    [47.06362933  3.95732642]   45.95971467    0.00339315\n",
      "90    [47.14704522  3.93324774]   45.94289299    0.00081737\n",
      "100   [47.18918086  3.92164893]   45.93882144    0.00019899\n",
      "110   [47.21045829  3.91603947]   45.93782626    0.00004887\n",
      "120   [47.22120004  3.91331634]   45.93758105    0.00001209\n",
      "130   [47.22662169  3.91198969]   45.93752023    0.00000301\n",
      "140   [47.22935759  3.91134122]   45.93750507    0.00000075\n",
      "150   [47.23073796  3.91102327]   45.93750127    0.00000019\n",
      "160   [47.23143431  3.91086694]   45.93750032    0.00000005\n",
      "170   [47.23178554  3.91078987]   45.93750008    0.00000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(172,\n",
       " array([47.23183127,  3.91077997]),\n",
       " 45.93750007064501,\n",
       " 9.079592189209507e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_desc_2(.0637)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
